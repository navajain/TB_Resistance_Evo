{"cells":[{"cell_type":"markdown","metadata":{"id":"QNFJM41UlDR5"},"source":["# Download CRyPTIC data\n","Unfortunately, there is a lot of data that needs to be downloaded... which is why it is convenient to do it in a separate notebook.\n","\n","Here are all the scripts you need to do that."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14428,"status":"ok","timestamp":1717017188797,"user":{"displayName":"Benson Kung","userId":"09507617451673917234"},"user_tz":420},"id":"53i08py0lD56","outputId":"5ecaff15-4a4e-4112-832d-196ccb22f667"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from tqdm import tqdm\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","evo_general_dir = '/content/drive/MyDrive/EVO/'\n","vcfs_dir = 'vcfs/'\n","cryptic_dir = 'cryptic_data/'\n","cryptic_reuse_csv = 'CRyPTIC_reuse_table_20231208.csv'"]},{"cell_type":"markdown","metadata":{"id":"BK4ihr7PltvS"},"source":["## Genotype data tables\n","See [this FTP directory](https://ftp.ebi.ac.uk/pub/databases/cryptic/release_june2022/reproducibility/data_tables/cryptic-analysis-group/). DATA_SCHEMA.pdf provides a good overview. Briefly, this section is for downloading everything BUT sample VCFs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEENh4CjmCjU"},"outputs":[],"source":["# files = ['VARIANTS.csv.gz', 'MUTATIONS.csv.gz', 'GENOMES.csv.gz']\n","files = ['GENOMES.csv.gz']\n","ftp_directory = 'ftp.ebi.ac.uk/pub/databases/cryptic/release_june2022/reproducibility/data_tables/cryptic-analysis-group/'\n","output_dir = evo_general_dir + cryptic_dir\n","\n","for file_name in files:\n","  to_download = ftp_directory + file_name\n","  !wget -P $output_dir $to_download"]},{"cell_type":"markdown","metadata":{"id":"ioOvL7dvnvKy"},"source":["## VCFs\n","Unlike the above, this section downloads sample VCFs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiW8hZ8foynO"},"outputs":[],"source":["# Download cryptic_reuse_csv\n","# !wget -P $evo_general_dir -q ftp://ftp.ebi.ac.uk/pub/databases/cryptic/\tftp.ebi.ac.uk/pub/databases/cryptic/release_june2022/reuse/CRyPTIC_reuse_table_20231208.csv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vFlp4un6n1gT"},"outputs":[],"source":["output_dir = evo_general_dir + vcfs_dir\n","\n","reuse_vcf = pd.read_csv(evo_general_dir + cryptic_reuse_csv)\n","\n","if not os.path.exists(output_dir):\n","  !mkdir $output_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"R7uRpfx9n6lT"},"outputs":[],"source":["def get_site(unique_id):\n","  return unique_id.split('.')[1]\n","\n","for i, row in tqdm(reuse_vcf.iterrows()):\n","  sample_directory = output_dir + \"site_\" + get_site(row['UNIQUEID']) + '/'\n","\n","  if not os.path.exists(sample_directory):\n","    !mkdir $sample_directory\n","\n","  to_download = 'ftp.ebi.ac.uk/pub/databases/cryptic/release_june2022/reproducibility/' + row['VCF']\n","\n","  file_name = row['VCF'].strip().split('/')[-1]\n","  if os.path.exists(sample_directory + file_name): continue\n","\n","  !wget -P $sample_directory -q $to_download"]},{"cell_type":"markdown","metadata":{"id":"FKpn4iYyt4tZ"},"source":["## Reference genome gumpy pickle + WGS creation\n","Because it can take over a minute to load a Genome, it is best to pickle the reference genome.\n","\n","However, we have discovered that loading a pickled Genome is not much faster than loading a VCF and \"adding\" it to a Genome. So, there's no need to pickle every M. tb genome.\n","\n","**Conclusion:** Creating a Genome object takes too much time in general. The best thing to do is, to store the whole sequence as a FASTA (i.e. just one string), and use \"primers\" to obtain the segments you are interested in."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"R6VN_1NHE7Ar","executionInfo":{"status":"ok","timestamp":1717017189754,"user_tz":420,"elapsed":152,"user":{"displayName":"Benson Kung","userId":"09507617451673917234"}}},"outputs":[],"source":["# # Uncomment this code if you have not created a .gbk file!\n","# # GeneBank has deprecated the .gbk format in favor of a new .gbff format\n","# # We can use Biopython to downgrade a .gbb file into a .gbk one\n","# # Download H37Rv .gbff file from NCBI Datasets: https://www.ncbi.nlm.nih.gov/datasets/genome/GCF_000195955.2/\n","\n","# from Bio import SeqIO\n","# reference_file = evo_general_dir + 'h37rv_genebank_flatfile.gbff'\n","# SeqIO.convert(reference_file, 'genbank', evo_general_dir + 'h37rv_genebank.gbk', 'genbank')\n","\n","# # This is important because .gbk works with gumpy, but not .gbff"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"zgdjb_y_J9rY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717017210632,"user_tz":420,"elapsed":19902,"user":{"displayName":"Benson Kung","userId":"09507617451673917234"}},"outputId":"c7f9bad9-3379-45e2-dcba-fb1c02aff1d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gumpy\n","  Downloading gumpy-1.2.7-py3-none-any.whl (48 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gumpy) (1.25.2)\n","Collecting pysam (from gumpy)\n","  Downloading pysam-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (22.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.0/22.0 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting biopython (from gumpy)\n","  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gumpy) (4.66.4)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from gumpy) (7.4.4)\n","Collecting pytest-cov (from gumpy)\n","  Downloading pytest_cov-5.0.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gumpy) (2.0.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gumpy) (1.11.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->gumpy) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gumpy) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gumpy) (2024.1)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->gumpy) (2.0.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->gumpy) (24.0)\n","Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->gumpy) (1.5.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->gumpy) (1.2.1)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->gumpy) (2.0.1)\n","Collecting coverage[toml]>=5.2.1 (from pytest-cov->gumpy)\n","  Downloading coverage-7.5.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->gumpy) (1.16.0)\n","Installing collected packages: pysam, coverage, biopython, pytest-cov, gumpy\n","Successfully installed biopython-1.83 coverage-7.5.3 gumpy-1.2.7 pysam-0.22.1 pytest-cov-5.0.0\n"]}],"source":["!pip install gumpy\n","\n","import gumpy as gp\n","import pickle\n","\n","# print(\"Loading reference genome...\")\n","# ref_genome = gp.Genome(evo_general_dir + 'h37rv_genebank.gbk', reference=True)\n","# pickle.dump(ref_genome, open(evo_general_dir + 'h37rv_genome.pkl', 'wb'))\n","# print(\"Done!\")\n","\n","# # how to load the data!\n","ref_genome = pickle.load(open(evo_general_dir + 'h37rv_genebank.pkl', 'rb'))\n","\n","# how to obtain a reference genome\n","genome = \"\".join(ref_genome.nucleotide_sequence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2SK4xTDmJuyA"},"outputs":[],"source":["evo_general_dir = '/content/drive/MyDrive/EVO/'\n","vcfs_dir = 'vcfs/'\n","cryptic_dir = 'cryptic_data/'\n","cryptic_reuse_csv = 'CRyPTIC_reuse_table_20231208.csv'\n","genomes_dir = 'genomes/'\n","\n","input_dir = evo_general_dir + vcfs_dir\n","reuse_vcf = pd.read_csv(evo_general_dir + cryptic_reuse_csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xdzfzk3tJYME"},"outputs":[],"source":["def get_site(unique_id):\n","  return unique_id.split('.')[1]\n","\n","for i, row in tqdm(reuse_vcf.iterrows()):\n","\n","  # check if the VCF file is present\n","  sample_directory = evo_general_dir + vcfs_dir + \"site_\" + get_site(row['UNIQUEID']) + '/'\n","  assert os.path.exists(sample_directory), \"Directory does not exist for sample \" + row['UNIQUEID']\n","\n","  file_name = row['VCF'].strip().split('/')[-1]\n","  assert os.path.exists(sample_directory + file_name), \"File does not exist for sample \" + row['UNIQUEID']\n","\n","  # check if the sample genome already exists\n","  if os.path.exists(evo_general_dir + genomes_dir + 'site_' + get_site(row['UNIQUEID']) + '/' + row['UNIQUEID'] + '.txt'): continue\n","\n","  # create genome\n","  file_path = sample_directory + file_name\n","  gunzip(file_path)\n","\n","  vcf = gp.VCFFile(file_path[:-3])\n","  gzip(file_path[:-3])\n","\n","  genome = gef.ref_genome + vcf\n","  genome_string = \"\".join(genome.nucleotide_sequence).upper()\n","\n","  # create a folder for the sample's site\n","  # if it does not already exist\n","  if not os.path.exists(evo_general_dir + genomes_dir + 'site_' + get_site(row['UNIQUEID'])):\n","    os.mkdir(evo_general_dir + genomes_dir + 'site_' + get_site(row['UNIQUEID']))\n","\n","  output_file_path = evo_general_dir + genomes_dir + 'site_' + get_site(row['UNIQUEID']) + '/' + row['UNIQUEID'] + '.txt'\n","  with open(output_file_path, 'w+') as f: f.write(genome_string)"]},{"cell_type":"markdown","source":["# Deprecated"],"metadata":{"id":"dL2FckBuqNUa"}},{"cell_type":"markdown","metadata":{"id":"UC6EOvo_o_a3"},"source":["### Converting embedding files to single sample files\n","Unfortunately, a file with 100 (500, 4096)-dimensional embeddings is 1.5 GB in size. To ease the load on computers with less CPU, this section takes embedding .npy files and splits them so that each sample gets its own file.\n","\n","Generally, the .npy files have been generated in other notebooks (see: evo_scratchwork and evo_general, which should be in the same folder as the current notebook.)"]},{"cell_type":"markdown","source":[],"metadata":{"id":"n6PT5RryqM2N"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8j5J4pk2V4U"},"outputs":[],"source":["evo_general_dir = '/content/drive/MyDrive/EVO/'\n","\n","embedding_dir = 'emb_embeddings_v1/'\n","embedding_sub_dir = 'embeds_1.0_left/'\n","sub_dirs = os.listdir(evo_general_dir + embedding_dir + embedding_sub_dir)\n","general_path = evo_general_dir + embedding_dir"]},{"cell_type":"code","source":["embed = np.load('/content/drive/MyDrive/EVO/rif_embeddings_v1/embeds_1.0_singles_last_index/site_02/site.02.subj.0001.lab.2014222001.iso.1.npy')"],"metadata":{"id":"1zIjd4ygN_UJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embed.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0fw9aFezOG3u","executionInfo":{"status":"ok","timestamp":1716933654709,"user_tz":420,"elapsed":137,"user":{"displayName":"Benson Kung","userId":"09507617451673917234"}},"outputId":"25767548-0684-4cc0-f22d-224e5618fe94"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4096,)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCGffoIg2u_x"},"outputs":[],"source":["\"\"\"\n","  Pick an embedding index to use. Create a file per embedding.\n","\"\"\"\n","emb_index = -1\n","count = 0\n","for sub_dir in tqdm(sub_dirs):\n","  directory = general_path + embedding_sub_dir + sub_dir + '/'\n","  files = os.listdir(directory)\n","  for f in files:\n","    count += 1\n","\n","  for f in tqdm(files):\n","    embed = np.load(directory + f)\n","    new_dir = general_path + 'embeds_1.0_singles_last_index/' + sub_dir + '/'\n","\n","    if not os.path.exists(new_dir):\n","      os.makedirs(new_dir)\n","\n","    if not os.path.exists(new_dir + f):\n","      np.save(new_dir + f, embed[0][emb_index])"]},{"cell_type":"markdown","source":["## Miscellaneous old code"],"metadata":{"id":"WNf1Xu2KzMJM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1716742849207,"user":{"displayName":"Benson Kung","userId":"09507617451673917234"},"user_tz":420},"id":"9eW1cOEW13yC","outputId":"d1327944-830b-4681-af05-886d339ed81a"},"outputs":[{"name":"stdout","output_type":"stream","text":["11\n"]}],"source":["# for (dirpath, dirnames, filenames) in walk(dir):\n","#   for filename in filenames:\n","#     if not filename.endswith('.npy'): continue\n","#     os.remove(dir + filename)\n","\n","import os\n","dir = evo_general_dir + embedding_dir + out_sub_dir\n","files = os.listdir(dir)\n","print(len(files))\n","# for (dirpath, dirnames, filenames) in walk(dir):\n","#   for filename in filenames:\n","#     if not filename.endswith('.npy'): continue\n","#     os.remove(dir + filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4B2MEhlHpC85"},"outputs":[],"source":["import numpy as np\n","\n","evo_general_dir = '/content/drive/MyDrive/EVO/'\n","\n","embedding_dir = 'rif_embeddings_v1/'\n","embedding_sub_dir = 'embeds_1.0/'\n","\n","out_sub_dir = 'embeds_1.0_singles/'\n","\n","# we use UNIQUEIDs to name our files\n","unique_ids = np.load(evo_general_dir + embedding_dir + 'unique_ids.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAroRc741NME"},"outputs":[],"source":["from os.path import exists\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5515,"status":"ok","timestamp":1716759938915,"user":{"displayName":"Benson Kung","userId":"09507617451673917234"},"user_tz":420},"id":"8q66wTk9tPMc","outputId":"9d82fd15-ad26-4462-f206-df6d819fdeb9"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 12259/12259 [00:05<00:00, 2313.59it/s]\n"]}],"source":["def get_site(unique_id):\n","  return unique_id.split('.')[1]\n","\n","missing_ids = []\n","small_files = []\n","dir = evo_general_dir + embedding_dir + out_sub_dir\n","for id in tqdm(unique_ids):\n","  file_name = dir + \"site_\" + get_site(id) + '/' + id + '.npy'\n","  if not exists(file_name):\n","    missing_ids.append(id)\n","  else:\n","    if os.path.getsize(file_name) < 1000000:\n","      print(os.path.getsize(file_name))\n","      small_files.append(id)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LfQVzNrTtItX"},"outputs":[],"source":["for id in tqdm(unique_ids):\n","  out_dir = evo_general_dir + embedding_dir + out_sub_dir + 'site_' + get_site(id) + '/'\n","  if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","  flag, embed = next(embeds)\n","  if flag == -1:\n","    current_file += 1\n","    embeds = get_embedding(evo_general_dir + embedding_dir + embedding_sub_dir + files[current_file])\n","\n","  np.save(out_dir + id + '.npy', embed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0cUTVx4TqLHY"},"outputs":[],"source":["from os import walk\n","\n","def get_embedding(file_name):\n","  embeds = np.load(file_name)\n","  for embed in embeds:\n","    yield 1, embed\n","\n","  yield -1, None\n","\n","def get_site(unique_id):\n","  return unique_id.split('.')[1]\n","\n","# get all of our embedding .npy files\n","files = []\n","for (dirpath, dirnames, filenames) in walk(evo_general_dir + embedding_dir + embedding_sub_dir):\n","  for filename in filenames:\n","    if not filename.endswith('.npy'): continue\n","    files.append(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Zbe-lUr3q8MV","outputId":"c07fb9b6-5b16-4b28-a2af-652e459ce4db"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 12262/12262 [56:55<00:00,  3.59it/s]\n"]}],"source":["current_file = 0\n","embeds =  get_embedding(evo_general_dir + embedding_dir + embedding_sub_dir + files[current_file])\n","for id in tqdm(unique_ids):\n","  out_dir = evo_general_dir + embedding_dir + out_sub_dir + 'site_' + get_site(id) + '/'\n","  if not os.path.exists(out_dir):\n","    os.makedirs(out_dir)\n","\n","  flag, embed = next(embeds)\n","  if flag == -1:\n","    current_file += 1\n","    embeds = get_embedding(evo_general_dir + embedding_dir + embedding_sub_dir + files[current_file])\n","\n","  np.save(out_dir + id + '.npy', embed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mA1k2wRjwhb6"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyNl8r0aIYzqNXpRPAqv8uTI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}